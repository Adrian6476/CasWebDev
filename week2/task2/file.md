**B1c Does your project involve any of the following? (please select all that apply).**

- [x] Secondary data relating to living individuals. This includes existing data collected from social media, or from other public or private sources. (Note that if the data has already been aggregated when you receive it, i.e. you are receiving a summary such as totals or averages rather than individual data, this does not require ethical review.)

**D2 Please provide a summary of the project, including its purpose, rationale, design and methods, making clear the importance to society or advancing field of research. & I1 Please provide information regarding the nature of the products or technologies and their intended destination and use.**

Specific datasets used include [Fairface](https://openaccess.thecvf.com/content/WACV2021/papers/Karkkainen_FairFace_Face_Attribute_Dataset_for_Balanced_Race_Gender_and_Age_WACV_2021_paper.pdf), which provides a balanced racial composition to mitigate bias. FairFace contains 108,501 images categorized into seven racial groups: White, Black, Indian, East Asian, Southeast Asian, Middle Eastern, and Latino. The images were collected from the YFCC100M Flickr dataset, Twitter, and online newspaper outlets. These images are annotated for race, gender, and age by multiple human annotators, providing a robust dataset for training and evaluation. According to the test results in the paper, the FairFace model has an accuracy difference of less than 1% between males and females, and between whites and non-whites in gender classification. The balanced dataset helps to train the models more effectively, reducing the risk of bias in facial recognition systems, which in turn ensures more equitable performance across different demographic groups. 

**I2 Please describe what steps you have taken to support responsible use and / or minimise the risk of misuse or other harms relating to their use.**

Fairface collects only the data necessary to fulfill research purposes, avoids excessive data collection, and follows the GDPR to ensure that data processing is lawful, transparent and fair, and that the rights of data subjects are upheld. It follows the ICO guidelines on facial image and biometric data to ensure that data is processed lawfully and provides justification and detailed information on the selection of datasets to ensure that it is ethical and reduces risks in the use of the data. Data annotation was done through Amazon Mechanical Turk, where multiple annotators jointly annotated an image to reduce the bias brought by a single annotator. Although the data is publicly available, measures need to be taken to ensure the privacy and security of the data and to prevent unauthorized access or use. The project also regularly evaluates and improves data processing processes, tests model performance on updated datasets, and monitors bias to ensure that the latest ethical and legal standards are followed.
